{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 아트 장르 트레인 통일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "original_dataset_dir = 'C:\\\\Users\\\\Affinity\\\\Downloads\\\\best-artworks-of-all-time\\\\images\\\\images\\\\'\n",
    "\n",
    "validation_dir = 'C:\\\\Users\\\\Affinity\\\\Documents\\\\img\\\\art\\\\art_genre_img\\\\validation'\n",
    "\n",
    "test_dir = 'C:\\\\Users\\\\Affinity\\\\Documents\\\\img\\\\art\\\\art_genre_img\\\\test'\n",
    "\n",
    "train_dir = 'C:\\\\Users\\\\Affinity\\\\Documents\\\\img\\\\art\\\\art_genre_img\\\\train2'\n",
    "\n",
    "l = os.listdir(original_dataset_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1200 images belonging to 6 classes.\n",
      "Found 480 images belonging to 6 classes.\n",
      "Found 480 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=90,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.7,\n",
    "    zoom_range=[0.9, 2.2],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(100, 100),\n",
    "    batch_size=20,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(100, 100),\n",
    "    batch_size=20,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(100, 100),\n",
    "    batch_size=20,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Baroque',\n",
       " 'High_Renaissance',\n",
       " 'Impressionism',\n",
       " 'Northern_Renaissance',\n",
       " 'Post_Impressionism',\n",
       " 'Symbolism']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2 = os.listdir(train_dir)\n",
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "\n",
    "# for i in l2:\n",
    "#     l_genre = os.listdir(train_dir + '/' + i)\n",
    "#     random.shuffle(l_genre)\n",
    "#     os.mkdir(train_dir + '/' + i + '2')\n",
    "#     for j in range(200):\n",
    "#         fname = l_genre[j]\n",
    "#         src = os.path.join(train_dir + '/' + i, fname)\n",
    "#         dst = os.path.join(train_dir + '/' + i + '2', fname)\n",
    "#         shutil.copyfile(src, dst)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1200 images belonging to 6 classes.\n",
      "Found 480 images belonging to 6 classes.\n",
      "Found 480 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                 include_top=False,\n",
    "                 input_shape=(100, 100, 3))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 3, 3, 512))\n",
    "    labels = np.zeros(shape=(sample_count, 6))\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(100, 100),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            # 제너레이터는 루프 안에서 무한하게 데이터를 만들어내므로 모든 이미지를 한 번씩 처리하고 나면 중지합니다\n",
    "            break\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_dir, 2000)\n",
    "validation_features, validation_labels = extract_features(validation_dir, 1000)\n",
    "test_features, test_labels = extract_features(test_dir, 1000)\n",
    "\n",
    "train_features = np.reshape(train_features, (2000, 3 * 3 * 512))\n",
    "validation_features = np.reshape(validation_features, (1000, 3 * 3 * 512))\n",
    "test_features = np.reshape(test_features, (1000, 3 * 3 * 512))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Affinity\\.conda\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/200\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 1.9472 - acc: 0.2210 - val_loss: 1.7264 - val_acc: 0.2880\n",
      "Epoch 2/200\n",
      "2000/2000 [==============================] - 1s 261us/step - loss: 1.6201 - acc: 0.3295 - val_loss: 1.6679 - val_acc: 0.3490\n",
      "Epoch 3/200\n",
      "2000/2000 [==============================] - 1s 258us/step - loss: 1.4535 - acc: 0.4325 - val_loss: 1.6502 - val_acc: 0.3710\n",
      "Epoch 4/200\n",
      "2000/2000 [==============================] - 1s 281us/step - loss: 1.3282 - acc: 0.5070 - val_loss: 1.6414 - val_acc: 0.3850\n",
      "Epoch 5/200\n",
      "2000/2000 [==============================] - 1s 261us/step - loss: 1.2571 - acc: 0.5355 - val_loss: 1.6252 - val_acc: 0.4000\n",
      "Epoch 6/200\n",
      "2000/2000 [==============================] - 1s 291us/step - loss: 1.1726 - acc: 0.5780 - val_loss: 1.6484 - val_acc: 0.3810\n",
      "Epoch 7/200\n",
      "2000/2000 [==============================] - 1s 277us/step - loss: 1.1107 - acc: 0.6130 - val_loss: 1.6530 - val_acc: 0.3740\n",
      "Epoch 8/200\n",
      "2000/2000 [==============================] - 1s 256us/step - loss: 1.0616 - acc: 0.6235 - val_loss: 1.6598 - val_acc: 0.4040\n",
      "Epoch 9/200\n",
      "2000/2000 [==============================] - 1s 265us/step - loss: 1.0259 - acc: 0.6315 - val_loss: 1.6623 - val_acc: 0.3960\n",
      "Epoch 10/200\n",
      "2000/2000 [==============================] - 1s 259us/step - loss: 0.9982 - acc: 0.6475 - val_loss: 1.6582 - val_acc: 0.4040\n",
      "Epoch 11/200\n",
      "2000/2000 [==============================] - 1s 283us/step - loss: 0.9652 - acc: 0.6555 - val_loss: 1.6952 - val_acc: 0.3790\n",
      "Epoch 12/200\n",
      "2000/2000 [==============================] - 1s 275us/step - loss: 0.9397 - acc: 0.6715 - val_loss: 1.6850 - val_acc: 0.4090\n",
      "Epoch 13/200\n",
      "2000/2000 [==============================] - 1s 265us/step - loss: 0.9112 - acc: 0.6880 - val_loss: 1.6883 - val_acc: 0.3910\n",
      "Epoch 14/200\n",
      "2000/2000 [==============================] - 1s 274us/step - loss: 0.8793 - acc: 0.6995 - val_loss: 1.7121 - val_acc: 0.3890\n",
      "Epoch 15/200\n",
      "2000/2000 [==============================] - 1s 268us/step - loss: 0.8452 - acc: 0.7165 - val_loss: 1.7045 - val_acc: 0.3890\n",
      "Epoch 16/200\n",
      "2000/2000 [==============================] - 1s 274us/step - loss: 0.8282 - acc: 0.7255 - val_loss: 1.6945 - val_acc: 0.4220\n",
      "Epoch 17/200\n",
      "2000/2000 [==============================] - 1s 268us/step - loss: 0.8106 - acc: 0.7210 - val_loss: 1.7255 - val_acc: 0.3880\n",
      "Epoch 18/200\n",
      "2000/2000 [==============================] - 1s 276us/step - loss: 0.7774 - acc: 0.7470 - val_loss: 1.7518 - val_acc: 0.3980\n",
      "Epoch 19/200\n",
      "2000/2000 [==============================] - 1s 272us/step - loss: 0.7623 - acc: 0.7500 - val_loss: 1.7588 - val_acc: 0.3970\n",
      "Epoch 20/200\n",
      "2000/2000 [==============================] - 1s 275us/step - loss: 0.7338 - acc: 0.7655 - val_loss: 1.7502 - val_acc: 0.4110\n",
      "Epoch 21/200\n",
      "2000/2000 [==============================] - 1s 267us/step - loss: 0.7345 - acc: 0.7580 - val_loss: 1.7737 - val_acc: 0.4160\n",
      "Epoch 22/200\n",
      "2000/2000 [==============================] - 1s 284us/step - loss: 0.7032 - acc: 0.7720 - val_loss: 1.7757 - val_acc: 0.4020\n",
      "Epoch 23/200\n",
      "2000/2000 [==============================] - 1s 267us/step - loss: 0.6863 - acc: 0.7785 - val_loss: 1.7572 - val_acc: 0.4110\n",
      "Epoch 24/200\n",
      "2000/2000 [==============================] - 1s 267us/step - loss: 0.6777 - acc: 0.7815 - val_loss: 1.7731 - val_acc: 0.4220\n",
      "Epoch 25/200\n",
      "2000/2000 [==============================] - 1s 267us/step - loss: 0.6556 - acc: 0.7990 - val_loss: 1.7887 - val_acc: 0.4250\n",
      "Epoch 26/200\n",
      "2000/2000 [==============================] - 1s 274us/step - loss: 0.6496 - acc: 0.7950 - val_loss: 1.7897 - val_acc: 0.4100\n",
      "Epoch 27/200\n",
      "2000/2000 [==============================] - 1s 275us/step - loss: 0.6434 - acc: 0.7995 - val_loss: 1.8040 - val_acc: 0.4290\n",
      "Epoch 28/200\n",
      "2000/2000 [==============================] - 1s 276us/step - loss: 0.6169 - acc: 0.8180 - val_loss: 1.7913 - val_acc: 0.4410\n",
      "Epoch 29/200\n",
      "2000/2000 [==============================] - 1s 274us/step - loss: 0.6036 - acc: 0.8175 - val_loss: 1.8089 - val_acc: 0.4420\n",
      "Epoch 30/200\n",
      "2000/2000 [==============================] - 1s 267us/step - loss: 0.5983 - acc: 0.8015 - val_loss: 1.8091 - val_acc: 0.4350\n",
      "Epoch 31/200\n",
      "2000/2000 [==============================] - 1s 283us/step - loss: 0.5762 - acc: 0.8255 - val_loss: 1.8304 - val_acc: 0.4190\n",
      "Epoch 32/200\n",
      "2000/2000 [==============================] - 1s 265us/step - loss: 0.5685 - acc: 0.8245 - val_loss: 1.8489 - val_acc: 0.4180\n",
      "Epoch 33/200\n",
      "2000/2000 [==============================] - 1s 275us/step - loss: 0.5484 - acc: 0.8390 - val_loss: 1.8410 - val_acc: 0.4240\n",
      "Epoch 34/200\n",
      "2000/2000 [==============================] - 1s 267us/step - loss: 0.5452 - acc: 0.8435 - val_loss: 1.8517 - val_acc: 0.4160\n",
      "Epoch 35/200\n",
      "2000/2000 [==============================] - 1s 292us/step - loss: 0.5382 - acc: 0.8495 - val_loss: 1.8529 - val_acc: 0.4180\n",
      "Epoch 36/200\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 0.5132 - acc: 0.8465 - val_loss: 1.8649 - val_acc: 0.4160\n",
      "Epoch 37/200\n",
      "2000/2000 [==============================] - 1s 275us/step - loss: 0.5135 - acc: 0.8470 - val_loss: 1.8620 - val_acc: 0.4270\n",
      "Epoch 38/200\n",
      "2000/2000 [==============================] - 1s 277us/step - loss: 0.4958 - acc: 0.8605 - val_loss: 1.8852 - val_acc: 0.4160\n",
      "Epoch 39/200\n",
      "2000/2000 [==============================] - 1s 273us/step - loss: 0.4905 - acc: 0.8590 - val_loss: 1.8895 - val_acc: 0.4230\n",
      "Epoch 40/200\n",
      "2000/2000 [==============================] - 1s 285us/step - loss: 0.4771 - acc: 0.8655 - val_loss: 1.8944 - val_acc: 0.4310\n",
      "Epoch 41/200\n",
      "2000/2000 [==============================] - 1s 273us/step - loss: 0.4806 - acc: 0.8695 - val_loss: 1.9016 - val_acc: 0.4240\n",
      "Epoch 42/200\n",
      "2000/2000 [==============================] - 1s 278us/step - loss: 0.4610 - acc: 0.8710 - val_loss: 1.9240 - val_acc: 0.4130\n",
      "Epoch 43/200\n",
      "2000/2000 [==============================] - 1s 282us/step - loss: 0.4475 - acc: 0.8745 - val_loss: 1.9215 - val_acc: 0.4160\n",
      "Epoch 44/200\n",
      "2000/2000 [==============================] - 1s 283us/step - loss: 0.4496 - acc: 0.8740 - val_loss: 1.9463 - val_acc: 0.4140\n",
      "Epoch 45/200\n",
      "2000/2000 [==============================] - 1s 283us/step - loss: 0.4188 - acc: 0.8845 - val_loss: 1.9507 - val_acc: 0.4190\n",
      "Epoch 46/200\n",
      "2000/2000 [==============================] - 1s 284us/step - loss: 0.4139 - acc: 0.8850 - val_loss: 1.9672 - val_acc: 0.4150\n",
      "Epoch 47/200\n",
      "2000/2000 [==============================] - 1s 283us/step - loss: 0.4190 - acc: 0.8875 - val_loss: 1.9677 - val_acc: 0.4110\n",
      "Epoch 48/200\n",
      "2000/2000 [==============================] - 1s 283us/step - loss: 0.4112 - acc: 0.8870 - val_loss: 1.9701 - val_acc: 0.4170\n",
      "Epoch 49/200\n",
      "2000/2000 [==============================] - 1s 283us/step - loss: 0.4097 - acc: 0.8880 - val_loss: 1.9621 - val_acc: 0.4150\n",
      "Epoch 50/200\n",
      "2000/2000 [==============================] - 1s 283us/step - loss: 0.3941 - acc: 0.8910 - val_loss: 1.9892 - val_acc: 0.4150\n",
      "Epoch 51/200\n",
      "2000/2000 [==============================] - 1s 276us/step - loss: 0.3834 - acc: 0.8965 - val_loss: 1.9835 - val_acc: 0.4170\n",
      "Epoch 52/200\n",
      "2000/2000 [==============================] - 1s 276us/step - loss: 0.3723 - acc: 0.9020 - val_loss: 2.0064 - val_acc: 0.4100\n",
      "Epoch 53/200\n",
      "2000/2000 [==============================] - 1s 289us/step - loss: 0.3705 - acc: 0.9110 - val_loss: 2.0110 - val_acc: 0.4120\n",
      "Epoch 54/200\n",
      "2000/2000 [==============================] - 1s 284us/step - loss: 0.3592 - acc: 0.9020 - val_loss: 2.0300 - val_acc: 0.4140\n",
      "Epoch 55/200\n",
      "2000/2000 [==============================] - 1s 283us/step - loss: 0.3486 - acc: 0.9140 - val_loss: 2.0406 - val_acc: 0.4130\n",
      "Epoch 56/200\n",
      "2000/2000 [==============================] - 1s 283us/step - loss: 0.3567 - acc: 0.9120 - val_loss: 2.0350 - val_acc: 0.4140\n",
      "Epoch 57/200\n",
      "2000/2000 [==============================] - 1s 292us/step - loss: 0.3422 - acc: 0.9185 - val_loss: 2.0333 - val_acc: 0.4190\n",
      "Epoch 58/200\n",
      "2000/2000 [==============================] - 1s 292us/step - loss: 0.3423 - acc: 0.9075 - val_loss: 2.0444 - val_acc: 0.4160\n",
      "Epoch 59/200\n",
      "2000/2000 [==============================] - 1s 291us/step - loss: 0.3364 - acc: 0.9210 - val_loss: 2.0452 - val_acc: 0.4110\n",
      "Epoch 60/200\n",
      "2000/2000 [==============================] - 1s 291us/step - loss: 0.3256 - acc: 0.9215 - val_loss: 2.0503 - val_acc: 0.4170\n",
      "Epoch 61/200\n",
      "2000/2000 [==============================] - 1s 284us/step - loss: 0.3227 - acc: 0.9215 - val_loss: 2.0565 - val_acc: 0.4150\n",
      "Epoch 62/200\n",
      "2000/2000 [==============================] - 1s 283us/step - loss: 0.3135 - acc: 0.9275 - val_loss: 2.0663 - val_acc: 0.4110\n",
      "Epoch 63/200\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 0.3052 - acc: 0.9295 - val_loss: 2.0680 - val_acc: 0.4150\n",
      "Epoch 64/200\n",
      "2000/2000 [==============================] - 1s 316us/step - loss: 0.2944 - acc: 0.9295 - val_loss: 2.0850 - val_acc: 0.4110\n",
      "Epoch 65/200\n",
      "2000/2000 [==============================] - 1s 290us/step - loss: 0.2878 - acc: 0.9385 - val_loss: 2.1219 - val_acc: 0.4120\n",
      "Epoch 66/200\n",
      "2000/2000 [==============================] - 1s 292us/step - loss: 0.2912 - acc: 0.9335 - val_loss: 2.1190 - val_acc: 0.4090\n",
      "Epoch 67/200\n",
      "2000/2000 [==============================] - 1s 291us/step - loss: 0.2839 - acc: 0.9395 - val_loss: 2.1158 - val_acc: 0.4110\n",
      "Epoch 68/200\n",
      "2000/2000 [==============================] - 1s 292us/step - loss: 0.2843 - acc: 0.9365 - val_loss: 2.1312 - val_acc: 0.4090\n",
      "Epoch 69/200\n",
      "2000/2000 [==============================] - 1s 292us/step - loss: 0.2768 - acc: 0.9390 - val_loss: 2.1278 - val_acc: 0.4170\n",
      "Epoch 70/200\n",
      "2000/2000 [==============================] - 1s 291us/step - loss: 0.2706 - acc: 0.9415 - val_loss: 2.1626 - val_acc: 0.4070\n",
      "Epoch 71/200\n",
      "2000/2000 [==============================] - 1s 292us/step - loss: 0.2661 - acc: 0.9440 - val_loss: 2.1472 - val_acc: 0.4120\n",
      "Epoch 72/200\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 0.2697 - acc: 0.9405 - val_loss: 2.1409 - val_acc: 0.4070\n",
      "Epoch 73/200\n",
      "2000/2000 [==============================] - 1s 292us/step - loss: 0.2538 - acc: 0.9490 - val_loss: 2.1637 - val_acc: 0.4110\n",
      "Epoch 74/200\n",
      "2000/2000 [==============================] - 1s 292us/step - loss: 0.2483 - acc: 0.9455 - val_loss: 2.1631 - val_acc: 0.4110\n",
      "Epoch 75/200\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 0.2453 - acc: 0.9495 - val_loss: 2.1910 - val_acc: 0.4080\n",
      "Epoch 76/200\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 0.2472 - acc: 0.9515 - val_loss: 2.1811 - val_acc: 0.4030\n",
      "Epoch 77/200\n",
      "2000/2000 [==============================] - 1s 291us/step - loss: 0.2379 - acc: 0.9470 - val_loss: 2.1936 - val_acc: 0.4010\n",
      "Epoch 78/200\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 0.2305 - acc: 0.9495 - val_loss: 2.2131 - val_acc: 0.4110\n",
      "Epoch 79/200\n",
      "2000/2000 [==============================] - 1s 292us/step - loss: 0.2352 - acc: 0.9470 - val_loss: 2.2146 - val_acc: 0.4090\n",
      "Epoch 80/200\n",
      "2000/2000 [==============================] - 1s 292us/step - loss: 0.2193 - acc: 0.9555 - val_loss: 2.2423 - val_acc: 0.4130\n",
      "Epoch 81/200\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 0.2234 - acc: 0.9490 - val_loss: 2.2559 - val_acc: 0.3980\n",
      "Epoch 82/200\n",
      "2000/2000 [==============================] - 1s 292us/step - loss: 0.2161 - acc: 0.9555 - val_loss: 2.2372 - val_acc: 0.4030\n",
      "Epoch 83/200\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 0.2075 - acc: 0.9590 - val_loss: 2.2463 - val_acc: 0.4050\n",
      "Epoch 84/200\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 0.2095 - acc: 0.9590 - val_loss: 2.2796 - val_acc: 0.4030\n",
      "Epoch 85/200\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 0.2039 - acc: 0.9595 - val_loss: 2.2603 - val_acc: 0.4010\n",
      "Epoch 86/200\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 0.2102 - acc: 0.9590 - val_loss: 2.2710 - val_acc: 0.4030\n",
      "Epoch 87/200\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 0.1982 - acc: 0.9600 - val_loss: 2.2918 - val_acc: 0.3990\n",
      "Epoch 88/200\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 0.1942 - acc: 0.9645 - val_loss: 2.3167 - val_acc: 0.3970\n",
      "Epoch 89/200\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 0.1934 - acc: 0.9640 - val_loss: 2.3374 - val_acc: 0.4030\n",
      "Epoch 90/200\n",
      "2000/2000 [==============================] - 1s 308us/step - loss: 0.1869 - acc: 0.9625 - val_loss: 2.3214 - val_acc: 0.4050\n",
      "Epoch 91/200\n",
      "2000/2000 [==============================] - 1s 343us/step - loss: 0.1873 - acc: 0.9625 - val_loss: 2.2889 - val_acc: 0.4030\n",
      "Epoch 92/200\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 0.1822 - acc: 0.9635 - val_loss: 2.3136 - val_acc: 0.4050\n",
      "Epoch 93/200\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 0.1839 - acc: 0.9640 - val_loss: 2.3484 - val_acc: 0.4070\n",
      "Epoch 94/200\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 0.1760 - acc: 0.9685 - val_loss: 2.3308 - val_acc: 0.4070\n",
      "Epoch 95/200\n",
      "2000/2000 [==============================] - 1s 310us/step - loss: 0.1666 - acc: 0.9730 - val_loss: 2.3566 - val_acc: 0.3990\n",
      "Epoch 96/200\n",
      "2000/2000 [==============================] - 1s 308us/step - loss: 0.1692 - acc: 0.9690 - val_loss: 2.3892 - val_acc: 0.3970\n",
      "Epoch 97/200\n",
      "2000/2000 [==============================] - 1s 307us/step - loss: 0.1630 - acc: 0.9695 - val_loss: 2.3884 - val_acc: 0.4070\n",
      "Epoch 98/200\n",
      "2000/2000 [==============================] - 1s 310us/step - loss: 0.1660 - acc: 0.9660 - val_loss: 2.3742 - val_acc: 0.4010\n",
      "Epoch 99/200\n",
      "2000/2000 [==============================] - 1s 307us/step - loss: 0.1603 - acc: 0.9765 - val_loss: 2.4124 - val_acc: 0.3930\n",
      "Epoch 100/200\n",
      "2000/2000 [==============================] - 1s 293us/step - loss: 0.1567 - acc: 0.9720 - val_loss: 2.4113 - val_acc: 0.3950\n",
      "Epoch 101/200\n",
      "2000/2000 [==============================] - 1s 317us/step - loss: 0.1558 - acc: 0.9735 - val_loss: 2.4127 - val_acc: 0.3930\n",
      "Epoch 102/200\n",
      "2000/2000 [==============================] - 1s 307us/step - loss: 0.1450 - acc: 0.9790 - val_loss: 2.4296 - val_acc: 0.3990\n",
      "Epoch 103/200\n",
      "2000/2000 [==============================] - 1s 308us/step - loss: 0.1498 - acc: 0.9715 - val_loss: 2.4177 - val_acc: 0.3990\n",
      "Epoch 104/200\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 0.1472 - acc: 0.9715 - val_loss: 2.4542 - val_acc: 0.3910\n",
      "Epoch 105/200\n",
      "2000/2000 [==============================] - 1s 308us/step - loss: 0.1411 - acc: 0.9755 - val_loss: 2.4567 - val_acc: 0.3890\n",
      "Epoch 106/200\n",
      "2000/2000 [==============================] - 1s 310us/step - loss: 0.1372 - acc: 0.9800 - val_loss: 2.5002 - val_acc: 0.3910\n",
      "Epoch 107/200\n",
      "2000/2000 [==============================] - 1s 308us/step - loss: 0.1360 - acc: 0.9775 - val_loss: 2.4482 - val_acc: 0.3970\n",
      "Epoch 108/200\n",
      "2000/2000 [==============================] - 1s 317us/step - loss: 0.1391 - acc: 0.9770 - val_loss: 2.4612 - val_acc: 0.3970\n",
      "Epoch 109/200\n",
      "2000/2000 [==============================] - 1s 309us/step - loss: 0.1340 - acc: 0.9770 - val_loss: 2.4886 - val_acc: 0.3990\n",
      "Epoch 110/200\n",
      "2000/2000 [==============================] - 1s 306us/step - loss: 0.1311 - acc: 0.9780 - val_loss: 2.5041 - val_acc: 0.3950\n",
      "Epoch 111/200\n",
      "2000/2000 [==============================] - 1s 317us/step - loss: 0.1253 - acc: 0.9800 - val_loss: 2.5018 - val_acc: 0.3970\n",
      "Epoch 112/200\n",
      "2000/2000 [==============================] - 1s 313us/step - loss: 0.1250 - acc: 0.9785 - val_loss: 2.5245 - val_acc: 0.3920\n",
      "Epoch 113/200\n",
      "2000/2000 [==============================] - 1s 308us/step - loss: 0.1236 - acc: 0.9835 - val_loss: 2.5275 - val_acc: 0.3950\n",
      "Epoch 114/200\n",
      "2000/2000 [==============================] - 1s 311us/step - loss: 0.1223 - acc: 0.9800 - val_loss: 2.5681 - val_acc: 0.3930\n",
      "Epoch 115/200\n",
      "2000/2000 [==============================] - 1s 306us/step - loss: 0.1184 - acc: 0.9810 - val_loss: 2.5486 - val_acc: 0.4030\n",
      "Epoch 116/200\n",
      "2000/2000 [==============================] - 1s 327us/step - loss: 0.1187 - acc: 0.9815 - val_loss: 2.5570 - val_acc: 0.3890\n",
      "Epoch 117/200\n",
      "2000/2000 [==============================] - 1s 346us/step - loss: 0.1142 - acc: 0.9810 - val_loss: 2.5427 - val_acc: 0.3990\n",
      "Epoch 118/200\n",
      "2000/2000 [==============================] - 1s 319us/step - loss: 0.1145 - acc: 0.9810 - val_loss: 2.5461 - val_acc: 0.3990\n",
      "Epoch 119/200\n",
      "2000/2000 [==============================] - 1s 325us/step - loss: 0.1147 - acc: 0.9805 - val_loss: 2.5713 - val_acc: 0.3910\n",
      "Epoch 120/200\n",
      "2000/2000 [==============================] - 1s 341us/step - loss: 0.1054 - acc: 0.9855 - val_loss: 2.5949 - val_acc: 0.3930\n",
      "Epoch 121/200\n",
      "2000/2000 [==============================] - 1s 360us/step - loss: 0.1106 - acc: 0.9855 - val_loss: 2.5751 - val_acc: 0.3950\n",
      "Epoch 122/200\n",
      "2000/2000 [==============================] - 1s 357us/step - loss: 0.1004 - acc: 0.9860 - val_loss: 2.6135 - val_acc: 0.3910\n",
      "Epoch 123/200\n",
      "2000/2000 [==============================] - 1s 341us/step - loss: 0.1018 - acc: 0.9830 - val_loss: 2.6199 - val_acc: 0.3930\n",
      "Epoch 124/200\n",
      "2000/2000 [==============================] - 1s 349us/step - loss: 0.1003 - acc: 0.9900 - val_loss: 2.6323 - val_acc: 0.3970\n",
      "Epoch 125/200\n",
      "2000/2000 [==============================] - 1s 342us/step - loss: 0.1030 - acc: 0.9850 - val_loss: 2.6279 - val_acc: 0.3820\n",
      "Epoch 126/200\n",
      "2000/2000 [==============================] - 1s 357us/step - loss: 0.0996 - acc: 0.9860 - val_loss: 2.6292 - val_acc: 0.3950\n",
      "Epoch 127/200\n",
      "2000/2000 [==============================] - 1s 368us/step - loss: 0.0941 - acc: 0.9850 - val_loss: 2.6884 - val_acc: 0.3930\n",
      "Epoch 128/200\n",
      "2000/2000 [==============================] - 1s 349us/step - loss: 0.0937 - acc: 0.9875 - val_loss: 2.6837 - val_acc: 0.3890\n",
      "Epoch 129/200\n",
      "2000/2000 [==============================] - 1s 358us/step - loss: 0.0943 - acc: 0.9845 - val_loss: 2.6675 - val_acc: 0.3970\n",
      "Epoch 130/200\n",
      "2000/2000 [==============================] - 1s 366us/step - loss: 0.0932 - acc: 0.9860 - val_loss: 2.6824 - val_acc: 0.3910\n",
      "Epoch 131/200\n",
      "2000/2000 [==============================] - 1s 332us/step - loss: 0.0941 - acc: 0.9845 - val_loss: 2.6968 - val_acc: 0.3950\n",
      "Epoch 132/200\n",
      "2000/2000 [==============================] - 1s 318us/step - loss: 0.0926 - acc: 0.9825 - val_loss: 2.6942 - val_acc: 0.3930\n",
      "Epoch 133/200\n",
      "2000/2000 [==============================] - 1s 323us/step - loss: 0.0829 - acc: 0.9880 - val_loss: 2.7324 - val_acc: 0.3890\n",
      "Epoch 134/200\n",
      "2000/2000 [==============================] - 1s 325us/step - loss: 0.0896 - acc: 0.9885 - val_loss: 2.7289 - val_acc: 0.3930\n",
      "Epoch 135/200\n",
      "2000/2000 [==============================] - 1s 317us/step - loss: 0.0824 - acc: 0.9880 - val_loss: 2.7538 - val_acc: 0.3920\n",
      "Epoch 136/200\n",
      "2000/2000 [==============================] - 1s 325us/step - loss: 0.0822 - acc: 0.9855 - val_loss: 2.7392 - val_acc: 0.3820\n",
      "Epoch 137/200\n",
      "2000/2000 [==============================] - 1s 325us/step - loss: 0.0827 - acc: 0.9860 - val_loss: 2.7281 - val_acc: 0.3910\n",
      "Epoch 138/200\n",
      "2000/2000 [==============================] - 1s 321us/step - loss: 0.0785 - acc: 0.9890 - val_loss: 2.7802 - val_acc: 0.3820\n",
      "Epoch 139/200\n",
      "2000/2000 [==============================] - 1s 320us/step - loss: 0.0754 - acc: 0.9885 - val_loss: 2.7907 - val_acc: 0.3910\n",
      "Epoch 140/200\n",
      "2000/2000 [==============================] - 1s 348us/step - loss: 0.0834 - acc: 0.9860 - val_loss: 2.7846 - val_acc: 0.3850\n",
      "Epoch 141/200\n",
      "2000/2000 [==============================] - 1s 325us/step - loss: 0.0748 - acc: 0.9890 - val_loss: 2.7648 - val_acc: 0.3930\n",
      "Epoch 142/200\n",
      "2000/2000 [==============================] - 1s 321us/step - loss: 0.0728 - acc: 0.9895 - val_loss: 2.7636 - val_acc: 0.3970\n",
      "Epoch 143/200\n",
      "2000/2000 [==============================] - 1s 321us/step - loss: 0.0739 - acc: 0.9890 - val_loss: 2.7843 - val_acc: 0.3870\n",
      "Epoch 144/200\n",
      "2000/2000 [==============================] - 1s 325us/step - loss: 0.0709 - acc: 0.9910 - val_loss: 2.8204 - val_acc: 0.3890\n",
      "Epoch 145/200\n",
      "2000/2000 [==============================] - 1s 316us/step - loss: 0.0705 - acc: 0.9890 - val_loss: 2.8152 - val_acc: 0.3890\n",
      "Epoch 146/200\n",
      "2000/2000 [==============================] - 1s 317us/step - loss: 0.0684 - acc: 0.9895 - val_loss: 2.8483 - val_acc: 0.3930\n",
      "Epoch 147/200\n",
      "2000/2000 [==============================] - 1s 333us/step - loss: 0.0676 - acc: 0.9915 - val_loss: 2.8442 - val_acc: 0.3830\n",
      "Epoch 148/200\n",
      "2000/2000 [==============================] - 1s 323us/step - loss: 0.0666 - acc: 0.9900 - val_loss: 2.8708 - val_acc: 0.3930\n",
      "Epoch 149/200\n",
      "2000/2000 [==============================] - 1s 317us/step - loss: 0.0652 - acc: 0.9895 - val_loss: 2.8675 - val_acc: 0.3830\n",
      "Epoch 150/200\n",
      "2000/2000 [==============================] - 1s 319us/step - loss: 0.0655 - acc: 0.9925 - val_loss: 2.8530 - val_acc: 0.3830\n",
      "Epoch 151/200\n",
      "2000/2000 [==============================] - 1s 322us/step - loss: 0.0621 - acc: 0.9910 - val_loss: 2.9052 - val_acc: 0.4010\n",
      "Epoch 152/200\n",
      "2000/2000 [==============================] - 1s 324us/step - loss: 0.0611 - acc: 0.9910 - val_loss: 2.8918 - val_acc: 0.3830\n",
      "Epoch 153/200\n",
      "2000/2000 [==============================] - 1s 321us/step - loss: 0.0599 - acc: 0.9905 - val_loss: 2.9236 - val_acc: 0.3890\n",
      "Epoch 154/200\n",
      "2000/2000 [==============================] - 1s 319us/step - loss: 0.0538 - acc: 0.9940 - val_loss: 2.9700 - val_acc: 0.3780\n",
      "Epoch 155/200\n",
      "2000/2000 [==============================] - 1s 317us/step - loss: 0.0602 - acc: 0.9915 - val_loss: 2.9539 - val_acc: 0.3810\n",
      "Epoch 156/200\n",
      "2000/2000 [==============================] - 1s 316us/step - loss: 0.0547 - acc: 0.9935 - val_loss: 2.9451 - val_acc: 0.3850\n",
      "Epoch 157/200\n",
      "2000/2000 [==============================] - 1s 323us/step - loss: 0.0532 - acc: 0.9960 - val_loss: 2.9248 - val_acc: 0.3830\n",
      "Epoch 158/200\n",
      "2000/2000 [==============================] - 1s 320us/step - loss: 0.0561 - acc: 0.9935 - val_loss: 2.9698 - val_acc: 0.3820\n",
      "Epoch 159/200\n",
      "2000/2000 [==============================] - 1s 323us/step - loss: 0.0567 - acc: 0.9930 - val_loss: 2.9861 - val_acc: 0.3930\n",
      "Epoch 160/200\n",
      "2000/2000 [==============================] - 1s 322us/step - loss: 0.0526 - acc: 0.9930 - val_loss: 2.9902 - val_acc: 0.3870\n",
      "Epoch 161/200\n",
      "2000/2000 [==============================] - 1s 327us/step - loss: 0.0535 - acc: 0.9930 - val_loss: 2.9814 - val_acc: 0.3950\n",
      "Epoch 162/200\n",
      "2000/2000 [==============================] - 1s 322us/step - loss: 0.0494 - acc: 0.9950 - val_loss: 3.0074 - val_acc: 0.3890\n",
      "Epoch 163/200\n",
      "2000/2000 [==============================] - 1s 316us/step - loss: 0.0500 - acc: 0.9935 - val_loss: 3.0097 - val_acc: 0.3870\n",
      "Epoch 164/200\n",
      "2000/2000 [==============================] - 1s 318us/step - loss: 0.0489 - acc: 0.9955 - val_loss: 3.0247 - val_acc: 0.3790\n",
      "Epoch 165/200\n",
      "2000/2000 [==============================] - 1s 352us/step - loss: 0.0465 - acc: 0.9935 - val_loss: 3.0571 - val_acc: 0.3800\n",
      "Epoch 166/200\n",
      "2000/2000 [==============================] - 1s 320us/step - loss: 0.0511 - acc: 0.9920 - val_loss: 3.0237 - val_acc: 0.3850\n",
      "Epoch 167/200\n",
      "2000/2000 [==============================] - 1s 321us/step - loss: 0.0463 - acc: 0.9940 - val_loss: 3.0232 - val_acc: 0.3830\n",
      "Epoch 168/200\n",
      "2000/2000 [==============================] - 1s 325us/step - loss: 0.0448 - acc: 0.9950 - val_loss: 3.0617 - val_acc: 0.3800\n",
      "Epoch 169/200\n",
      "2000/2000 [==============================] - 1s 318us/step - loss: 0.0493 - acc: 0.9920 - val_loss: 3.0334 - val_acc: 0.3910\n",
      "Epoch 170/200\n",
      "2000/2000 [==============================] - 1s 319us/step - loss: 0.0453 - acc: 0.9950 - val_loss: 3.0635 - val_acc: 0.3910\n",
      "Epoch 171/200\n",
      "2000/2000 [==============================] - 1s 320us/step - loss: 0.0442 - acc: 0.9960 - val_loss: 3.0755 - val_acc: 0.3870\n",
      "Epoch 172/200\n",
      "2000/2000 [==============================] - 1s 319us/step - loss: 0.0397 - acc: 0.9955 - val_loss: 3.0706 - val_acc: 0.3910\n",
      "Epoch 173/200\n",
      "2000/2000 [==============================] - 1s 318us/step - loss: 0.0445 - acc: 0.9945 - val_loss: 3.1033 - val_acc: 0.3800\n",
      "Epoch 174/200\n",
      "2000/2000 [==============================] - 1s 320us/step - loss: 0.0408 - acc: 0.9955 - val_loss: 3.0893 - val_acc: 0.3870\n",
      "Epoch 175/200\n",
      "2000/2000 [==============================] - 1s 322us/step - loss: 0.0425 - acc: 0.9945 - val_loss: 3.0991 - val_acc: 0.3850\n",
      "Epoch 176/200\n",
      "2000/2000 [==============================] - 1s 320us/step - loss: 0.0390 - acc: 0.9950 - val_loss: 3.1363 - val_acc: 0.3850\n",
      "Epoch 177/200\n",
      "2000/2000 [==============================] - 1s 326us/step - loss: 0.0389 - acc: 0.9940 - val_loss: 3.1531 - val_acc: 0.3850\n",
      "Epoch 178/200\n",
      "2000/2000 [==============================] - 1s 322us/step - loss: 0.0383 - acc: 0.9960 - val_loss: 3.1588 - val_acc: 0.3800\n",
      "Epoch 179/200\n",
      "2000/2000 [==============================] - 1s 325us/step - loss: 0.0357 - acc: 0.9950 - val_loss: 3.1709 - val_acc: 0.3830\n",
      "Epoch 180/200\n",
      "2000/2000 [==============================] - 1s 321us/step - loss: 0.0382 - acc: 0.9955 - val_loss: 3.1662 - val_acc: 0.3820\n",
      "Epoch 181/200\n",
      "2000/2000 [==============================] - 1s 323us/step - loss: 0.0356 - acc: 0.9965 - val_loss: 3.2032 - val_acc: 0.3850\n",
      "Epoch 182/200\n",
      "2000/2000 [==============================] - 1s 321us/step - loss: 0.0345 - acc: 0.9970 - val_loss: 3.2141 - val_acc: 0.3790\n",
      "Epoch 183/200\n",
      "2000/2000 [==============================] - 1s 321us/step - loss: 0.0335 - acc: 0.9965 - val_loss: 3.2274 - val_acc: 0.3780\n",
      "Epoch 184/200\n",
      "2000/2000 [==============================] - 1s 318us/step - loss: 0.0332 - acc: 0.9950 - val_loss: 3.2265 - val_acc: 0.3840\n",
      "Epoch 185/200\n",
      "2000/2000 [==============================] - 1s 318us/step - loss: 0.0322 - acc: 0.9955 - val_loss: 3.2179 - val_acc: 0.3810\n",
      "Epoch 186/200\n",
      "2000/2000 [==============================] - 1s 328us/step - loss: 0.0350 - acc: 0.9935 - val_loss: 3.2107 - val_acc: 0.3870\n",
      "Epoch 187/200\n",
      "2000/2000 [==============================] - 1s 317us/step - loss: 0.0310 - acc: 0.9980 - val_loss: 3.2438 - val_acc: 0.3850\n",
      "Epoch 188/200\n",
      "2000/2000 [==============================] - 1s 327us/step - loss: 0.0329 - acc: 0.9955 - val_loss: 3.2602 - val_acc: 0.3910\n",
      "Epoch 189/200\n",
      "2000/2000 [==============================] - 1s 323us/step - loss: 0.0330 - acc: 0.9950 - val_loss: 3.2480 - val_acc: 0.3790\n",
      "Epoch 190/200\n",
      "2000/2000 [==============================] - 1s 350us/step - loss: 0.0293 - acc: 0.9975 - val_loss: 3.2947 - val_acc: 0.3880\n",
      "Epoch 191/200\n",
      "2000/2000 [==============================] - 1s 320us/step - loss: 0.0314 - acc: 0.9965 - val_loss: 3.2822 - val_acc: 0.3840\n",
      "Epoch 192/200\n",
      "2000/2000 [==============================] - 1s 325us/step - loss: 0.0307 - acc: 0.9980 - val_loss: 3.2772 - val_acc: 0.3870\n",
      "Epoch 193/200\n",
      "2000/2000 [==============================] - 1s 318us/step - loss: 0.0277 - acc: 0.9975 - val_loss: 3.3029 - val_acc: 0.3870\n",
      "Epoch 194/200\n",
      "2000/2000 [==============================] - 1s 322us/step - loss: 0.0301 - acc: 0.9970 - val_loss: 3.3237 - val_acc: 0.3840\n",
      "Epoch 195/200\n",
      "2000/2000 [==============================] - 1s 322us/step - loss: 0.0285 - acc: 0.9975 - val_loss: 3.3444 - val_acc: 0.3790\n",
      "Epoch 196/200\n",
      "2000/2000 [==============================] - 1s 316us/step - loss: 0.0273 - acc: 0.9975 - val_loss: 3.3634 - val_acc: 0.3770\n",
      "Epoch 197/200\n",
      "2000/2000 [==============================] - 1s 321us/step - loss: 0.0254 - acc: 0.9985 - val_loss: 3.3572 - val_acc: 0.3850\n",
      "Epoch 198/200\n",
      "2000/2000 [==============================] - 1s 320us/step - loss: 0.0283 - acc: 0.9980 - val_loss: 3.3260 - val_acc: 0.3870\n",
      "Epoch 199/200\n",
      "2000/2000 [==============================] - 1s 328us/step - loss: 0.0265 - acc: 0.9980 - val_loss: 3.3774 - val_acc: 0.3820\n",
      "Epoch 200/200\n",
      "2000/2000 [==============================] - 1s 323us/step - loss: 0.0248 - acc: 0.9975 - val_loss: 3.3767 - val_acc: 0.3870\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_dim=3 * 3 * 512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(6, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    epochs=200,\n",
    "                    batch_size=20,\n",
    "                    validation_data=(validation_features, validation_labels))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# from keras.optimizers import Adam\n",
    "\n",
    "# from keras.applications import VGG16\n",
    "\n",
    "# conv_base = VGG16(weights='imagenet',\n",
    "#                  include_top=False,\n",
    "#                  input_shape=(100, 100, 3))\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(conv_base)\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "# adam = Adam()\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#              optimizer=adam,\n",
    "#              metrics=['acc'])\n",
    "\n",
    "\n",
    "# history = model.fit_generator(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=100,\n",
    "#     epochs=300,\n",
    "#     validation_data=validation_generator,\n",
    "#     validation_steps=150\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Affinity\\.conda\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Affinity\\.conda\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Affinity\\.conda\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "100/100 [==============================] - 52s 524ms/step - loss: 2.0546 - acc: 0.2435 - val_loss: 1.7007 - val_acc: 0.2470\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 51s 511ms/step - loss: 1.4656 - acc: 0.4310 - val_loss: 1.6552 - val_acc: 0.3400\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 53s 529ms/step - loss: 1.0914 - acc: 0.5970 - val_loss: 1.6516 - val_acc: 0.3160\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 54s 545ms/step - loss: 0.4981 - acc: 0.8310 - val_loss: 1.8160 - val_acc: 0.3300\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 0.3101 - acc: 0.9065 - val_loss: 2.0453 - val_acc: 0.3140\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 56s 564ms/step - loss: 0.0980 - acc: 0.9715 - val_loss: 2.5614 - val_acc: 0.3560\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 55s 547ms/step - loss: 0.0629 - acc: 0.9795 - val_loss: 3.0379 - val_acc: 0.3350\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 55s 551ms/step - loss: 0.0502 - acc: 0.9860 - val_loss: 3.3433 - val_acc: 0.3510\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 0.0327 - acc: 0.9895 - val_loss: 3.6428 - val_acc: 0.3080\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 56s 555ms/step - loss: 0.0080 - acc: 0.9985 - val_loss: 3.8641 - val_acc: 0.3540\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 58s 580ms/step - loss: 0.1177 - acc: 0.9780 - val_loss: 3.3880 - val_acc: 0.3250\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 58s 581ms/step - loss: 0.0067 - acc: 0.9990 - val_loss: 3.7376 - val_acc: 0.3480\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 60s 599ms/step - loss: 0.0327 - acc: 0.9895 - val_loss: 3.7774 - val_acc: 0.3380\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 62s 621ms/step - loss: 7.1235e-04 - acc: 1.0000 - val_loss: 4.2099 - val_acc: 0.3440\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 60s 602ms/step - loss: 0.0889 - acc: 0.9820 - val_loss: 3.3711 - val_acc: 0.3230\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 57s 571ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 4.0823 - val_acc: 0.3140\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 56s 564ms/step - loss: 0.0017 - acc: 0.9995 - val_loss: 4.3291 - val_acc: 0.3300\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 56s 557ms/step - loss: 0.0318 - acc: 0.9915 - val_loss: 3.7593 - val_acc: 0.3380\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 60s 601ms/step - loss: 3.6482e-04 - acc: 1.0000 - val_loss: 4.4681 - val_acc: 0.3270\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 61s 613ms/step - loss: 0.1332 - acc: 0.9855 - val_loss: 3.5736 - val_acc: 0.3300\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 59s 592ms/step - loss: 0.0032 - acc: 0.9995 - val_loss: 4.3458 - val_acc: 0.3060\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 59s 585ms/step - loss: 3.0647e-04 - acc: 1.0000 - val_loss: 4.6421 - val_acc: 0.3250\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 57s 574ms/step - loss: 1.2702e-04 - acc: 1.0000 - val_loss: 5.3675 - val_acc: 0.3210\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 59s 587ms/step - loss: 0.2035 - acc: 0.9725 - val_loss: 4.0431 - val_acc: 0.3090\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 59s 589ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 4.5322 - val_acc: 0.3330\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 60s 599ms/step - loss: 0.0260 - acc: 0.9955 - val_loss: 4.4668 - val_acc: 0.2960\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 67s 672ms/step - loss: 3.0981e-04 - acc: 1.0000 - val_loss: 5.1503 - val_acc: 0.3080\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 60s 596ms/step - loss: 0.0193 - acc: 0.9940 - val_loss: 5.2068 - val_acc: 0.3050\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 59s 591ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 5.1447 - val_acc: 0.2960\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 60s 603ms/step - loss: 1.9677e-04 - acc: 1.0000 - val_loss: 5.2440 - val_acc: 0.3190\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 58s 579ms/step - loss: 3.8192e-05 - acc: 1.0000 - val_loss: 5.7255 - val_acc: 0.3170\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 59s 593ms/step - loss: 0.0335 - acc: 0.9930 - val_loss: 4.7659 - val_acc: 0.2990\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 59s 587ms/step - loss: 2.8764e-04 - acc: 1.0000 - val_loss: 5.9637 - val_acc: 0.2720\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 59s 587ms/step - loss: 0.1217 - acc: 0.9800 - val_loss: 4.9143 - val_acc: 0.2980\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 62s 617ms/step - loss: 0.0018 - acc: 0.9995 - val_loss: 5.2763 - val_acc: 0.3070\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 58s 584ms/step - loss: 1.1757e-04 - acc: 1.0000 - val_loss: 5.8462 - val_acc: 0.3110\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 58s 577ms/step - loss: 0.1632 - acc: 0.9800 - val_loss: 4.9883 - val_acc: 0.3010\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 57s 573ms/step - loss: 0.0074 - acc: 0.9990 - val_loss: 5.2002 - val_acc: 0.3210\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 57s 571ms/step - loss: 1.6678e-04 - acc: 1.0000 - val_loss: 5.5246 - val_acc: 0.3140\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 57s 569ms/step - loss: 0.0159 - acc: 0.9960 - val_loss: 5.5287 - val_acc: 0.2670\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 58s 580ms/step - loss: 1.3289e-04 - acc: 1.0000 - val_loss: 5.6529 - val_acc: 0.2970\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 59s 588ms/step - loss: 3.6352e-05 - acc: 1.0000 - val_loss: 5.9157 - val_acc: 0.2950\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 61s 605ms/step - loss: 0.2145 - acc: 0.9760 - val_loss: 5.2575 - val_acc: 0.2890\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 60s 596ms/step - loss: 5.7924e-04 - acc: 1.0000 - val_loss: 5.6040 - val_acc: 0.3150\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 59s 594ms/step - loss: 0.0167 - acc: 0.9960 - val_loss: 5.4157 - val_acc: 0.3140\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 59s 585ms/step - loss: 1.8914e-04 - acc: 1.0000 - val_loss: 5.6758 - val_acc: 0.3150\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 60s 598ms/step - loss: 0.0534 - acc: 0.9890 - val_loss: 5.1855 - val_acc: 0.2740\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 59s 591ms/step - loss: 0.0060 - acc: 0.9985 - val_loss: 5.6233 - val_acc: 0.2900\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 57s 570ms/step - loss: 4.9457e-04 - acc: 1.0000 - val_loss: 6.4502 - val_acc: 0.2830\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 58s 580ms/step - loss: 0.0070 - acc: 0.9985 - val_loss: 6.3212 - val_acc: 0.2800\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (5, 5), activation='relu',\n",
    "         input_shape=(100, 100, 3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(64, (4, 4), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adadelta',\n",
    "             metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Untitled",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-keras] *",
   "language": "python",
   "name": "conda-env-.conda-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
