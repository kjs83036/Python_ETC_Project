{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:04<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " crawling complete\n",
      "\n",
      " modifier complete\n",
      "\n",
      " filter complete\n",
      "                                   title    area pay         time recently  \\\n",
      "0   [최고단가] 기본일급 88,125원/ 6.5시간 근무/ 경력자.장  서울 관악구  일급  17:00~24:00     10분전   \n",
      "1      [일일알바] 평가 아르바이트 패널 모집 (1시간/20000)  서울 전체   시급         시간협의     15분전   \n",
      "2        장지역 (장기,단기,하루) 당일지급 홈쇼핑 상품 반품작업  서울 송파구  일급  09:00~18:00     16분전   \n",
      "3                      연극 어플개발 관련 하루단기알바  서울 전체   시급         시간협의     18분전   \n",
      "4         [단기근무/주부사원환영] 코스트코 양재점 가전제품 판촉  서울 서초구  일급  10:00~19:00     20분전   \n",
      "5      [25일,26일,27일작업 3일지급]서울,분당선 실내무대사무  서울 전체   일급         시간협의     27분전   \n",
      "6          강남역/꿀알바/DB손해보험 강남사업단에서 일일지점체험  서울 강남구  일급  09:00~12:00     30분전   \n",
      "7        하루가능,선택근무가능/익일지급/70,240원/단순포장정리  서울 강동구  일급  09:00~18:00     42분전   \n",
      "8         [단기가능/바로근무/익일지급가능/양천향교역부근 ] 가양  서울 강서구  시급         시간협의     42분전   \n",
      "9         [단기가능/바로근무/익일지급가능/양천향교역부근 ] 가양  서울 강서구  시급         시간협의     42분전   \n",
      "10        서울,경기권 집기 및 부업하실분 모집합니다(부업,단기,  서울 전체   일급  09:00~05:00     47분전   \n",
      "11     급]강서,양천] 현금호송 보안 알바모집/ 12월26일(내일하  서울 양천구  일급         시간협의     56분전   \n",
      "12        [유니에스] 현대백화점 천호점 단기근로자(아르바이트)   서울 강동구  일급         시간협의     1시간전   \n",
      "13        [유니에스] 현대백화점 천호점 단기근로자(아르바이트)   서울 강동구  일급         시간협의     1시간전   \n",
      "14  [최고단가] 기본일급 88,125원/ 6.5시간 근무/ 경력자.장  서울 동작구  일급  17:00~24:00     1시간전   \n",
      "15        즐겁게 일하기 좋은곳+초보대환영+쉬운알바+셔틀,중식+주  서울 전체   일급  09:00~18:00     1시간전   \n",
      "\n",
      "                                                 link  \n",
      "0   http://www.albamon.com//recruit/view/gi?AL_GI_...  \n",
      "1   http://www.albamon.com//recruit/view/gi?AL_GI_...  \n",
      "2   http://www.albamon.com//recruit/view/gi?AL_GI_...  \n",
      "3   http://www.albamon.com//recruit/view/gi?AL_GI_...  \n",
      "4   http://www.albamon.com//recruit/view/gi?AL_GI_...  \n",
      "5   http://www.albamon.com//recruit/view/gi?AL_GI_...  \n",
      "6   http://www.albamon.com//recruit/view/gi?AL_GI_...  \n",
      "7   http://www.albamon.com//recruit/view/gi?AL_GI_...  \n",
      "8   http://www.albamon.com//recruit/view/gi?AL_GI_...  \n",
      "9   http://www.albamon.com//recruit/view/gi?AL_GI_...  \n",
      "10  http://www.albamon.com//recruit/view/gi?AL_GI_...  \n",
      "11  http://www.albamon.com//recruit/view/gi?AL_GI_...  \n",
      "12  http://www.albamon.com//recruit/view/gi?AL_GI_...  \n",
      "13  http://www.albamon.com//recruit/view/gi?AL_GI_...  \n",
      "14  http://www.albamon.com//recruit/view/gi?AL_GI_...  \n",
      "15  http://www.albamon.com//recruit/view/gi?AL_GI_...  \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Alba():\n",
    "    def __init__(self):\n",
    "\n",
    "        self.flag = False\n",
    "        self.result_list = []\n",
    "        self.words = [\"물류\", \"상차\", \"하차\", \"상하차\", \"투잡\", \"배달\", \"식기\", \n",
    "                     \"세척\", \"발렛\", \"쿠팡\", \"남여\", \"드라마\", \"품평회\", \"허브\",\n",
    "                     \"생동성\", \"임상시험\", \"전화\", \"서빙\", \"엑스트라\", \"영화\", \n",
    "                     \"조리보조\", \"주방\", \"남녀\", \"고3\", \"피킹\", \"Picking\", \n",
    "                     \"냉장\", \"오렌지라이프\", \"누구나\", \"택배\", \"분류\",\n",
    "                      \"연회장\", \"판매\"]\n",
    "        self.data = pd.DataFrame(columns=[\"title\", \"area\", \"pay\", \"time\", \"recently\", \"link\"])\n",
    "\n",
    "    def crawler(self, number_pages):\n",
    "\n",
    "        for page in tqdm(range(1, number_pages+1)):\n",
    "            req = requests.get('http://www.albamon.com/list/gi/mon_gi_list.asp?page=' +str(page)+'&gubun=2&ps=50&ob=6&lvtype=1&rArea=,I000&sDutyTerm=,5,10,20&gender=M&gender_chk=1&rAge=31&rAge_Chk=1&rWDate=1&Empmnt_Type=&tc=529')\n",
    "            req.encoding = None\n",
    "            html = req.text\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            result_title = soup.select(\"#subcontent > form > div.gListWrap > table > tbody > tr > td.subject > div > p.cTit > a\")\n",
    "            result_area = soup.select(\"#subcontent > form > div.gListWrap > table > tbody > tr > td.area > div\")\n",
    "            result_pay = soup.select(\"#subcontent > form > div.gListWrap > table > tbody > tr > td.pay > p > img\")\n",
    "            result_recently = soup.select(\"#subcontent > form > div.gListWrap > table > tbody > tr > td.recently > em\")\n",
    "\n",
    "            for i in range(len(result_title)):\n",
    "                self.data = self.data.append({\"title\" : result_title[i].text, \n",
    "                                            \"area\" : result_area[i].text, \n",
    "                                            \"pay\" : result_pay[i]['alt'],\n",
    "                                            \"time\" : result_pay[i].findNext(\"td\").text,\n",
    "                                            \"recently\" : result_recently[i].text,\n",
    "                                            \"link\" : \"http://www.albamon.com/\" + result_title[i][\"href\"]\n",
    "                                            },\n",
    "                                            ignore_index=True)\n",
    "                    \n",
    "        print(\"\\n\",\"crawling complete\")\n",
    "\n",
    "\n",
    "    def modifier(self):\n",
    "        self.data[\"area\"] = self.data[\"area\"].apply(lambda x: x[6:-1] if True else x)\n",
    "        self.data[\"time\"] = self.data[\"time\"].apply(lambda x: x[7:-7] if True else x)\n",
    "        # self.data[\"recently\"] = self.data[\"recently\"].apply(lambda x: str(datetime.now().hour+9) + \"시\" + str(datetime.now().minute - int(x[:2])) + \"분\" if x[-2:] == \"분전\" and len(x) == 4 else x)\n",
    "        # self.data[\"recently\"] = self.data[\"recently\"].apply(lambda x: str(datetime.now().hour+9) + \"시\" + str(datetime.now().minute - int(x[0])) + \"분\" if x[-2:] == \"분전\" and len(x) == 3 else x)\n",
    "        # self.data[\"recently\"] = self.data[\"recently\"].apply(lambda x: str(datetime.now().hour+9 - int(x[0])) + \"시\" + str(datetime.now().minute)+ \"분\" if x[-2:] == \"간전\" else x)\n",
    "\n",
    "        print(\"\\n\",\"modifier complete\")\n",
    "\n",
    "    def filter(self):\n",
    "        drop_index_list = []\n",
    "        for i in range(len(self.data)):\n",
    "            for j in self.words:\n",
    "                if j in self.data.title[i]:\n",
    "                    drop_index_list.append(i)\n",
    "                    continue\n",
    "        self.data = self.data.drop(drop_index_list, axis=0)\n",
    "        self.data = self.data.reset_index(drop=True)\n",
    "\n",
    "        print(\"\\n\",\"filter complete\")\n",
    "\n",
    "alba = Alba()\n",
    "alba.crawler(2)\n",
    "alba.modifier()\n",
    "alba.filter()\n",
    "print(alba.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
